* measure if realtime spectrogram extraction during training is viable
    * 27ms for a 4s spectrogram extraction. That's probably too slow. Can this be parallelized across multiple clips?

* extract non-scaled spectrograms so C can be tuned afterwards (+ we can use the librosa approach to compare)

at the spectrogram level:
* implement additive / multiplicative noise
* implement random equalization augmentation
* implement time stretching
* implement freq/pitch shifting
* implement non-integer time shifting


* implement L2 version of Crammer and Singer hinge loss
    * version with sum over labels
    * version with max over incorrect labels

* add refilter layers after convolution layers to reduce the number of parameters

* add more augmentation methods: non-integer shifts, small frequency shifts, time stretching (use scikit-image code from kaggle-galaxies)

* confusion matrices could be very informative, compute them


* loss can still be NaN for softmax + crossentropy, using the clipped crossentropy is a bit of a hack. Is there a cleaner way to solve this?
