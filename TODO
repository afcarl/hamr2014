* implement L2 version of Crammer and Singer hinge loss
    * version with sum over labels
    * version with max over incorrect labels

* add refilter layers after convolution layers to reduce the number of parameters

* add more augmentation methods: non-integer shifts, small frequency shifts, time stretching (use scikit-image code from kaggle-galaxies)

* confusion matrices could be very informative, compute them


* loss can still be NaN for softmax + crossentropy, using the clipped crossentropy is a bit of a hack. Is there a cleaner way to solve this?
