* add a separate convlayer whose features are globally max-pooled (not shared with the mean pooling), then concatenate both. Should be useful for the gunshots?

* average over several fixed perturbations for evaluation to get a better estimate (and probably improved score)!
    * implement build_chunk_fixed


* try reducing spectrogram compression, or use the librosa method
* consider different numbers of frequency components as well

* extend build_chunk to do more augmentation:
    * additive / multiplicative noise
    * random equalization augmentation
    * volume increase / decrease is linear in the pre-compressed domain, but nonlinear afterwards, so include this as well!

* confusion matrices could be very informative, compute them
* look at worst predicted examples (visualise them)

* try logistic + crossentropy again, but this time with the correct loss (i.e. not average binary crossentropy).

* add a decreasing learning rate schedule



* speed up augmentation: replace for loop over the chunk with mp.Pool#imap

* try 2D convolution
    * maybe + constant Q



---

* consider doing the spectrogram extraction on the GPU, with data loaded onto the GPU per batch. This might be fast enough and allows for: 
    * changing window sizes / hop sizes
    * augmentation in the time domain
        - time stretching and frequency shifting should be easier in the frequency domain though (need a time-freq representation for this anyway)
