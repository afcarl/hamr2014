* implement a new build_chunk function to do more advanced augmentation at the spectrogram level:
    * non-integer time shifting
    * non-integer freq shifting

    * time stretching

    * additive / multiplicative noise

    * random equalization augmentation

    - use scikit-image (look into how to do this again)
    - don't forget to apply compression afterwards



* average over perturbations at test time!

* consider doing the spectrogram extraction on the GPU, with data loaded onto the GPU per batch. This might be fast enough and allows for: 
    * changing window sizes / hop sizes
    * augmentation in the time domain
        - time stretching and frequency shifting should be easier in the frequency domain though (need a time-freq representation for this anyway)



* add more augmentation methods: non-integer shifts, small frequency shifts, time stretching (use scikit-image code from kaggle-galaxies)

* confusion matrices could be very informative, compute them


* loss can still be NaN for softmax + crossentropy, using the clipped crossentropy is a bit of a hack. Is there a cleaner way to solve this?
